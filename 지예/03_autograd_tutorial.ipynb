{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "03-autograd_tutorial.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yagkje_zmO1J",
        "colab_type": "text"
      },
      "source": [
        "# Autograd: automatic differentiation\n",
        "\n",
        "The ``autograd`` package provides automatic differentiation for all operations\n",
        "on Tensors. It is a define-by-run framework, which means that your backprop is\n",
        "defined by how your code is run, and that every single iteration can be\n",
        "different."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWfw7BNcnSnK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "7e5c2710-81b0-4c98-cdc7-60b66d52d553"
      },
      "source": [
        "!pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==0.3.0.post4\n",
            "\u001b[?25l  Downloading http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl (592.3MB)\n",
            "\u001b[K     |████████████████████████████████| 592.3MB 1.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (3.13)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==0.3.0.post4) (1.18.5)\n",
            "\u001b[31mERROR: torchvision 0.7.0+cu101 has requirement torch==1.6.0, but you'll have torch 0.3.0.post4 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.61 has requirement torch>=1.0.0, but you'll have torch 0.3.0.post4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "Successfully installed torch-0.3.0.post4\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (7.0.0)\n",
            "Collecting torch==1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/38/53/914885a93a44b96c0dd1c36f36ff10afe341f091230aad68f7228d61db1e/torch-1.6.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8MB 23kB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.6.0->torchvision) (0.16.0)\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 0.3.0.post4\n",
            "    Uninstalling torch-0.3.0.post4:\n",
            "      Successfully uninstalled torch-0.3.0.post4\n",
            "Successfully installed torch-1.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg_MzDc8mO1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCjY7WFFmO1a",
        "colab_type": "text"
      },
      "source": [
        "Create a tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-HciauamO1b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e3a4b142-51c7-4acf-a4c3-a00ed3beb810"
      },
      "source": [
        "# Create a 2x2 tensor with gradient-accumulation capabilities\n",
        "x = torch.tensor([[1, 2], [3, 4]], requires_grad=True, dtype=torch.float32)\n",
        "print(x)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FaU7wpLmO1i",
        "colab_type": "text"
      },
      "source": [
        "Do an operation on the tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2UTUQClmO1k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "959ac9b9-b52b-4e4d-9973-39efa290a8f0"
      },
      "source": [
        "# Deduct 2 from all elements\n",
        "y = x - 2\n",
        "print(y)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.,  0.],\n",
            "        [ 1.,  2.]], grad_fn=<SubBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7AGF9XdmO1t",
        "colab_type": "text"
      },
      "source": [
        "``y`` was created as a result of an operation, so it has a ``grad_fn``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0EvShy3mO1u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63d38e71-8aad-48ff-956c-f9f3ff3e39b5"
      },
      "source": [
        "print(y.grad_fn)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<SubBackward0 object at 0x7fb5f21ee940>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqEqHmsbmO12",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7207c066-f388-49f2-a87e-b328c348aff8"
      },
      "source": [
        "# What's happening here?\n",
        "print(x.grad_fn)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0LPddvrmO19",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "321237a5-c99b-49c2-cca4-b0472459471b"
      },
      "source": [
        "# Let's dig further...\n",
        "y.grad_fn"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<SubBackward0 at 0x7fb5f21ee908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDfS0frWmO2K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea960980-80db-45d0-c78e-f5a5b3d51c08"
      },
      "source": [
        "y.grad_fn.next_functions[0][0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<AccumulateGrad at 0x7fb60c7f9fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy5oGJU7mO2R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "a7f124d1-7f9c-42fd-aa3c-197bbde31c6f"
      },
      "source": [
        "y.grad_fn.next_functions[0][0].variable"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 4.]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ivg5fl0mO2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "19c3524d-e501-4b67-904d-507bcc0232eb"
      },
      "source": [
        "# Do more operations on y\n",
        "z = y * y * 3\n",
        "a = z.mean()  # average\n",
        "\n",
        "print(z)\n",
        "print(a)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 3.,  0.],\n",
            "        [ 3., 12.]], grad_fn=<MulBackward0>)\n",
            "tensor(4.5000, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4F06lN5mO2f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "4c4b410a-41e6-46d2-c1b1-b32f55c3918d"
      },
      "source": [
        "# Let's visualise the computational graph! (thks @szagoruyko)\n",
        "!pip3 install torchviz"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n",
            "\r\u001b[K     |████████                        | 10kB 25.5MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.6.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.18.5)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.1-cp36-none-any.whl size=3523 sha256=e4b1ffd0e99d952494c6a870416a5e9c8b9a5836c737b0391dbbc2999b80e9b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtncP7fxoWiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchviz import make_dot"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcZTsMW8mO2l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "403a02ae-7bcc-4c42-d874-54792b610606"
      },
      "source": [
        "make_dot(a)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fb5a24bb0f0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"106pt\" height=\"271pt\"\n viewBox=\"0.00 0.00 106.00 271.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 267)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-267 102,-267 102,4 -4,4\"/>\n<!-- 140418088881624 -->\n<g id=\"node1\" class=\"node\">\n<title>140418088881624</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"98,-21 0,-21 0,0 98,0 98,-21\"/>\n<text text-anchor=\"middle\" x=\"49\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MeanBackward0</text>\n</g>\n<!-- 140419421020568 -->\n<g id=\"node2\" class=\"node\">\n<title>140419421020568</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"94.5,-78 3.5,-78 3.5,-57 94.5,-57 94.5,-78\"/>\n<text text-anchor=\"middle\" x=\"49\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 140419421020568&#45;&gt;140418088881624 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140419421020568&#45;&gt;140418088881624</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M49,-56.7787C49,-49.6134 49,-39.9517 49,-31.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"52.5001,-31.1732 49,-21.1732 45.5001,-31.1732 52.5001,-31.1732\"/>\n</g>\n<!-- 140418088645576 -->\n<g id=\"node3\" class=\"node\">\n<title>140418088645576</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"94.5,-135 3.5,-135 3.5,-114 94.5,-114 94.5,-135\"/>\n<text text-anchor=\"middle\" x=\"49\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 140418088645576&#45;&gt;140419421020568 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140418088645576&#45;&gt;140419421020568</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M49,-113.7787C49,-106.6134 49,-96.9517 49,-88.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"52.5001,-88.1732 49,-78.1732 45.5001,-88.1732 52.5001,-88.1732\"/>\n</g>\n<!-- 140419427920136 -->\n<g id=\"node4\" class=\"node\">\n<title>140419427920136</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"94,-192 4,-192 4,-171 94,-171 94,-192\"/>\n<text text-anchor=\"middle\" x=\"49\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SubBackward0</text>\n</g>\n<!-- 140419427920136&#45;&gt;140418088645576 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140419427920136&#45;&gt;140418088645576</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M43.5885,-170.7787C42.3317,-163.6134 41.9599,-153.9517 42.4733,-145.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"45.9738,-145.498 43.597,-135.1732 39.0164,-144.7267 45.9738,-145.498\"/>\n</g>\n<!-- 140419427920136&#45;&gt;140418088645576 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140419427920136&#45;&gt;140418088645576</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.4115,-170.7787C55.6683,-163.6134 56.0401,-153.9517 55.5267,-145.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"58.9836,-144.7267 54.403,-135.1732 52.0262,-145.498 58.9836,-144.7267\"/>\n</g>\n<!-- 140419870466000 -->\n<g id=\"node5\" class=\"node\">\n<title>140419870466000</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"76,-263 22,-263 22,-228 76,-228 76,-263\"/>\n<text text-anchor=\"middle\" x=\"49\" y=\"-235.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (2, 2)</text>\n</g>\n<!-- 140419870466000&#45;&gt;140419427920136 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140419870466000&#45;&gt;140419427920136</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M49,-227.6724C49,-219.8405 49,-210.5893 49,-202.4323\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"52.5001,-202.2234 49,-192.2234 45.5001,-202.2235 52.5001,-202.2234\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffHhfJB4mO2s",
        "colab_type": "text"
      },
      "source": [
        "## Gradients\n",
        "\n",
        "Let's backprop now `out.backward()` is equivalent to doing `out.backward(torch.tensor([1.0]))`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-Fwq1QcmO2u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "f580d743-4689-41bd-baf6-64971c01bba5"
      },
      "source": [
        "# Backprop\n",
        "a.backward()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-decee06d7466>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the saved intermediate results have already been freed. Specify retain_graph=True when calling backward the first time."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmqFmXqRmO20",
        "colab_type": "text"
      },
      "source": [
        "Print gradients $\\frac{\\text{d}a}{\\text{d}x}$.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76W8GxPmmO21",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d451c41b-8d20-4e07-b700-961a690b5907"
      },
      "source": [
        "# Compute it by hand BEFORE executing this\n",
        "print(x.grad)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p-YzZxemO27",
        "colab_type": "text"
      },
      "source": [
        "You can do many crazy things with autograd!\n",
        "> With Great *Flexibility* Comes Great Responsibility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF12v14umO28",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "deb4db66-0b8d-46da-a65e-435d5a54e267"
      },
      "source": [
        "# Dynamic graphs!\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "i = 0\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "    i += 1\n",
        "print(y)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1037.2921, 1040.0750, 1321.5338], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4HvI7JVmO3D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3c5d8b6-b314-4560-de2e-984cc7f65573"
      },
      "source": [
        "# If we don't run backward on a scalar we need to specify the grad_output\n",
        "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
        "y.backward(gradients)\n",
        "\n",
        "print(x.grad)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zc3CeFfmO3J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dcb9088e-1f0b-489c-c032-e63911f06e74"
      },
      "source": [
        "# BEFORE executing this, can you tell what would you expect it to print?\n",
        "print(i)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJbxL3WomO3P",
        "colab_type": "text"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAmHwUxvmO3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This variable decides the tensor's range below\n",
        "n = 3"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHk3mL4JmO3Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "f52b6943-7f36-4d52-9b44-a82aac2ad3ba"
      },
      "source": [
        "# Both x and w that allows gradient accumulation\n",
        "x = torch.arange(1., n + 1, requires_grad=True)\n",
        "w = torch.ones(n, requires_grad=True)\n",
        "z = w @ x\n",
        "z.backward()\n",
        "print(x.grad, w.grad, sep='\\n')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1.])\n",
            "tensor([1., 2., 3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzrrg-uMmO3i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2009d644-92e3-4c0f-f34a-87d33a50a060"
      },
      "source": [
        "# Only w that allows gradient accumulation\n",
        "x = torch.arange(1., n + 1)\n",
        "w = torch.ones(n, requires_grad=True)\n",
        "z = w @ x\n",
        "z.backward()\n",
        "print(x.grad, w.grad, sep='\\n')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n",
            "tensor([1., 2., 3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eT9xESamO3p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c5561a13-d76e-47f6-c9f8-529eaf8f89a2"
      },
      "source": [
        "x = torch.arange(1., n + 1)\n",
        "w = torch.ones(n, requires_grad=True)\n",
        "\n",
        "# Regardless of what you do in this context, all torch tensors will not have gradient accumulation\n",
        "with torch.no_grad():\n",
        "    z = w @ x\n",
        "\n",
        "try:\n",
        "    z.backward()  # PyTorch will throw an error here, since z has no grad accum.\n",
        "except RuntimeError as e:\n",
        "    print('RuntimeError!!! >:[')\n",
        "    print(e)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RuntimeError!!! >:[\n",
            "element 0 of tensors does not require grad and does not have a grad_fn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I17rSVd_mO3y",
        "colab_type": "text"
      },
      "source": [
        "## More stuff\n",
        "\n",
        "Documentation of the automatic differentiation package is at\n",
        "http://pytorch.org/docs/autograd."
      ]
    }
  ]
}